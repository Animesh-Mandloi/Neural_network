{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189f9116-678f-4923-beca-418bb878ccf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Que 1. What is deep learning, and how is it connected to artificial intelligence?\n",
    "\n",
    "Deep learning is a subset of machine learning, which is itself a branch of artificial intelligence (AI).\n",
    "It involves using algorithms known as neural networks, designed to simulate the way humans learn and process information.\n",
    "Deep learning models are especially good at handling large datasets and performing tasks like image recognition,\n",
    "speech recognition, and natural language processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70680a6c-4c89-4f42-891b-f8383543b3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Que2. What is a neural network, and what are the different types of neural networks?\n",
    "\n",
    "A neural network is a computational model inspired by the human brain.\n",
    "It consists of layers of nodes (or neurons) connected by links,\n",
    "where each node represents a mathematical operation. \n",
    "There are different types of neural networks, including:\n",
    "\n",
    "Feedforward Neural Networks (FNN): The simplest type, where information moves in one direction from input to output.\n",
    "Convolutional Neural Networks (CNNs): Often used for image recognition tasks.\n",
    "Recurrent Neural Networks (RNNs): Used for sequential data, like time-series or text.\n",
    "Generative Adversarial Networks (GANs): Used for generating new data,\n",
    "like images or text, by pitting two networks against each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5216ebb8-858d-489c-93dd-1cd3dc028d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Que3. What is the mathematical structure of a neural network?\n",
    "Mathematically, a neural network can be represented as a set of functions, where each layer performs a transformation of the input data.\n",
    "For each layer, we have weights (parameters) and biases, and the output of each neuron is computed as a weighted sum of the inputs,\n",
    "followed by an activation function.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65683d4a-8799-4556-bfac-b86a3ab598b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Que4. What is an activation function, and why is it essential in neural networks?\n",
    "An activation function introduces non-linearity to the model, which allows it to learn complex patterns in the data. \n",
    "Without activation functions, a neural network would simply be a linear model,\n",
    "unable to capture complex relationships.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036754e1-5866-49b5-81d5-8858904225ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Que5. Could you list some common activation functions used in neural networks?\n",
    "Some common activation functions are:\n",
    "\n",
    "Sigmoid: Outputs values between 0 and 1, often used in binary classification.\n",
    "ReLU (Rectified Linear Unit): The most common function in deep networks, it outputs zero for negative inputs and passes positive values unchanged.\n",
    "Tanh (Hyperbolic Tangent): Outputs values between -1 and 1, often used in hidden layers.\n",
    "Softmax: Used in the output layer for multi-class classification, giving probabilities for each class.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93368228-dfed-43f6-9287-407c823568ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Que6. What is a multilayer neural network?\n",
    "A multilayer neural network is a type of neural network that has more than one layer of neurons. These are often called deep neural networks,\n",
    "and they are capable of learning more complex patterns by using multiple hidden layers between the input and output layers.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020cee79-c548-4b5b-82a8-3e54229a3965",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Que7. What is a loss function, and why is it crucial for neural network training?\n",
    "\n",
    "A loss function (also known as a cost function) is a measure of how far the network's predictions are from the true values.\n",
    "The goal during training is to minimize this loss,which improves the accuracy of the model.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290620e2-d290-42b7-a15d-69a6203e89ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Que8. What are some common types of loss functions?\n",
    "\n",
    "Some common loss functions include:\n",
    "\n",
    "Mean Squared Error (MSE): Used in regression tasks.\n",
    "Cross-Entropy Loss: Common in classification tasks, especially when there are multiple classes.\n",
    "Hinge Loss: Often used in Support Vector Machines, but can also be used in neural networks for classification.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c2db61-bd5c-43bf-93d3-5214553b6e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Que9. How does a neural network learn?\n",
    "\n",
    "A neural network learns through a process of optimization, where it adjusts its weights and biases to minimize the loss function.\n",
    "This process typically involves forward propagation (to calculate outputs) and backpropagation (to update parameters).'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b636ea-0ca3-4061-9782-183f50c9edab",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Que10. What is an optimizer in neural networks, and why is it necessary?\n",
    "\n",
    "An optimizer is an algorithm that adjusts the network's parameters (weights and biases) during training to minimize the loss function. \n",
    "It's necessary because it helps find the best set of parameters to improve model performance.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aab729b-1c2e-48e5-9ab6-8d390c012a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Que11. Could you briefly describe some common optimizers?\n",
    "\n",
    "Some common optimizers are:\n",
    "\n",
    "Stochastic Gradient Descent (SGD): A simple and popular optimization technique.\n",
    "Adam: A more advanced optimizer that adapts the learning rate for each parameter.\n",
    "RMSprop: An optimizer that adjusts the learning rate for each parameter based on past gradients.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c889e7f-f5f4-442b-91bf-075529cc65e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Que12. Can you explain forward and backward propagation in a neural network?\n",
    "\n",
    "Forward Propagation: The input data is passed through the network, layer by layer, until the output is obtained.\n",
    "\n",
    "Backward Propagation: The error (loss) is propagated back through the network, adjusting the weights using techniques like gradient descent to minimize the error.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48249a7d-f503-4b4c-9b21-29395853a7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Que13. What is weight initialization, and how does it impact training?\n",
    "\n",
    "Weight initialization refers to the method used to set the initial values of the weights in a neural network.\n",
    "Proper initialization is critical because poor initial weights can slow down training or lead to poor performance. \n",
    "Common strategies include random initialization or using techniques like Xavier\n",
    "or He initialization to avoid vanishing or exploding gradients.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7048971d-3653-450e-9d8a-8980af18b768",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Que14. What is the vanishing gradient problem in deep learning?\n",
    "\n",
    "The vanishing gradient problem occurs when the gradients (used to update weights) become very small during backpropagation, especially in deep networks. \n",
    "This can prevent the network from learning properly, as the weights don't update effectively.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb422447-4ec4-4e5f-a83c-2a24576a317a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Que15. What is the exploding gradient problem?\n",
    "\n",
    "The exploding gradient problem happens when the gradients grow exponentially during backpropagation. \n",
    "This can lead to unstable training and cause the networkâ€™s weights to overflow, making training difficult or impossible.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2576417-91b2-43ed-991d-26a327b4235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "               # practical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c87279d-c276-4665-ae0e-85d5cfe2c6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. How do you create a simple perceptron for basic binary classification?\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(1, input_dim=2, activation='sigmoid')) \n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c59f59-a413-46b7-b213-c31d48e6c36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. How can you build a neural network with one hidden layer using Keras?\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(8, input_dim=2, activation='relu'))  \n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cab149b-8c86-4590-8143-6bafef847874",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. How do you initialize weights using the Xavier (Glorot) initialization method in Keras?\n",
    "\n",
    "from keras.initializers import GlorotUniform\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=2, activation='relu', kernel_initializer=GlorotUniform()))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a532b26-e282-4357-99a9-5be75bac7061",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. How can you apply different activation functions in a neural network in Keras?\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=2, activation='relu'))   \n",
    "model.add(Dense(4, activation='tanh'))                \n",
    "model.add(Dense(1, activation='sigmoid'))             \n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878a65d5-d2fe-47b4-b6a5-8f0090ac2115",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. How do you add dropout to a neural network model to prevent overfitting?\n",
    "\n",
    "from keras.layers import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=2, activation='relu'))\n",
    "model.add(Dropout(0.2))  \n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dd8bd7-9540-4a12-83fd-7d4d41c2c3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. How do you manually implement forward propagation in a simple neural network?\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "weights = np.array([[0.1, 0.2], [0.3, 0.4]])  \n",
    "biases = np.array([0.5, 0.6])  \n",
    "\n",
    "X = np.array([1, 2])\n",
    "\n",
    "z = np.dot(weights, X) + biases\n",
    "output = 1 / (1 + np.exp(-z))  \n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1e2b7d-ef81-4caf-9e3b-916f3a345e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. How do you add batch normalization to a neural network model in Keras?\n",
    "\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=2, activation='relu'))\n",
    "model.add(BatchNormalization())  \n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb42b82-16b8-4482-82a0-02d766b0663b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. How can you visualize the training process with accuracy and loss curves?\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Value')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8512e2c2-0c53-4787-b112-d3d0f6c7134f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. How can you use gradient clipping in Keras to control the gradient size and prevent exploding gradients?\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "optimizer = Adam(clipvalue=1.0)  \n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c46100a-15f3-4932-95f4-96719bbb4fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10. How can you create a custom loss function in Keras?\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    return K.mean(K.square(y_true - y_pred))  \n",
    "    \n",
    "model.compile(optimizer='adam', loss=custom_loss, metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b4f3e6-7093-413f-85c3-deb96a49d103",
   "metadata": {},
   "outputs": [],
   "source": [
    "#11. How can you visualize the structure of a neural network model in Keras?\n",
    "\n",
    "from keras.utils import plot_model\n",
    "\n",
    "plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab707dc8-9cf1-49c6-979e-8744658bed41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5588bfa-0b5c-4635-a3d6-5ed9882be8e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dbcf4c-844a-414e-bb5d-cac1bdd71e62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
